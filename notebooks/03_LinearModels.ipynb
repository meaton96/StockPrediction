{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b3b4e8c-1ba1-45b8-8441-635eb1da4fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from src.data_eng.pipeline import run_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00920394",
   "metadata": {},
   "source": [
    "Create Config\n",
    "\n",
    "add additional interaction features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "111e191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import Config\n",
    "\n",
    "conf = Config(\n",
    "    #features=[], all features\n",
    "    add_int_features=True,\n",
    "    target={'horizon': 5, 'threshold': 0.01},\n",
    "   # ticker_list=['AAPL','META'], #all tickers\n",
    "    validate_cutoff='2022-01-01',      # FINAL TEST START\n",
    "    fold_len='365D',\n",
    "    fold_mode='expanding',             # or 'sliding'\n",
    "    sliding_train_years=None,          # set e.g. 5 if using sliding\n",
    "    embargo_days=None                  # defaults to horizon=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce3891c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin fetching data from yfinance...\n",
      "['AAPL', 'MSFT', 'NVDA', 'GOOGL', 'AMZN', 'META', 'TSLA', 'AVGO', 'TSM', 'ORCL', 'WMT', 'JPM', 'INTC', 'UNH', 'HD']\n",
      "saved: ../data/raw/AAPL.csv\n",
      "saved: ../data/raw/MSFT.csv\n",
      "saved: ../data/raw/NVDA.csv\n",
      "saved: ../data/raw/GOOGL.csv\n",
      "saved: ../data/raw/AMZN.csv\n",
      "saved: ../data/raw/META.csv\n",
      "saved: ../data/raw/TSLA.csv\n",
      "saved: ../data/raw/AVGO.csv\n",
      "saved: ../data/raw/TSM.csv\n",
      "saved: ../data/raw/ORCL.csv\n",
      "saved: ../data/raw/WMT.csv\n",
      "saved: ../data/raw/JPM.csv\n",
      "saved: ../data/raw/INTC.csv\n",
      "saved: ../data/raw/UNH.csv\n",
      "saved: ../data/raw/HD.csv\n",
      "done fetching data\n",
      "being data cleaning...\n",
      "done cleaning data\n",
      "begin feature engineering\n",
      "make features for AAPL\n",
      "make features for MSFT\n",
      "make features for NVDA\n",
      "make features for GOOGL\n",
      "make features for AMZN\n",
      "make features for META\n",
      "make features for TSLA\n",
      "make features for AVGO\n",
      "make features for TSM\n",
      "make features for ORCL\n",
      "make features for WMT\n",
      "make features for JPM\n",
      "make features for INTC\n",
      "make features for UNH\n",
      "make features for HD\n",
      "Done egineering features\n",
      "writing csvs...\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/AAPL.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/MSFT.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/NVDA.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/GOOGL.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/AMZN.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/META.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/TSLA.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/AVGO.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/TSM.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/ORCL.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/WMT.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/JPM.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/INTC.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/UNH.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/HD.csv\n"
     ]
    }
   ],
   "source": [
    "run_pipeline(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60b84920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c83fcc",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6c23af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best parameters: {'linearsvc__C': np.float64(0.00115279871282324)}\n",
      "Best score: 0.5315366314729787\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from src.data_eng.get_data import get_train_test_data\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "\n",
    "X_test, y_test, X_train, y_train = get_train_test_data(conf)\n",
    "\n",
    "def numeric_only(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "X_train = numeric_only(X_train).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "X_test  = numeric_only(X_test).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(with_mean=False),\n",
    "    LinearSVC(\n",
    "        max_iter=10000,\n",
    "        loss=\"hinge\",          # fixed as requested\n",
    "        dual=True,             # hinge requires dual=True\n",
    "        class_weight=\"balanced\"  # fixed as requested\n",
    "    )\n",
    ")\n",
    "# params\n",
    "param_dist = {\n",
    "    \"linearsvc__C\": loguniform(1e-3, 1) # reduced search area to low C to speed up\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,                   \n",
    "    scoring=\"roc_auc\",           \n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "print(\"Best score:\", search.best_score_)\n",
    "\n",
    "best_C = search.best_params_['linearsvc__C'] # 0.00115279871282324\n",
    "\n",
    "best_model = search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0cd598",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4027ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import LinearSVC\n",
    "# 1) build preprocessor with imputation to kill NaNs from lags/rolls\n",
    "def make_global_pipeline(numeric_cols, C):\n",
    "    pre = ColumnTransformer([\n",
    "        (\"num\", Pipeline([\n",
    "            (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scale\", StandardScaler())\n",
    "        ]), numeric_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), [\"__ticker__\"]),\n",
    "    ])\n",
    "    return Pipeline([\n",
    "        (\"pre\", pre),\n",
    "        (\"clf\", LinearSVC(\n",
    "            penalty=\"l2\",\n",
    "            loss=\"hinge\",           \n",
    "            dual=True,             \n",
    "            class_weight=\"balanced\",\n",
    "            C=C,\n",
    "            max_iter=20000,         \n",
    "            random_state=42\n",
    "        ))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24831215",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "from src.data_eng.folds import load_multi_ticker_collection\n",
    "from src.modeling.global_pairs import build_global_fold_pairs, build_global_insample_and_test\n",
    "\n",
    "# 1) get data\n",
    "collection = load_multi_ticker_collection(conf)\n",
    "\n",
    "# 2) build global fold pairs\n",
    "pairs = build_global_fold_pairs(collection)\n",
    "\n",
    "cv_scores = []\n",
    "for k, (Xtr, ytr, Xva, yva) in enumerate(pairs):\n",
    "    num_cols = [c for c in Xtr.columns if c not in (\"__ticker__\", \"Date\")]\n",
    "    \n",
    "    # align drops: build a mask from *X* then apply to X and y\n",
    "    mask_tr = Xtr[num_cols].isna().any(axis=1)\n",
    "    Xtr = Xtr.loc[~mask_tr]\n",
    "    ytr = ytr.loc[~mask_tr]\n",
    "\n",
    "    mask_va = Xva[num_cols].isna().any(axis=1)\n",
    "    Xva = Xva.loc[~mask_va]\n",
    "    yva = yva.loc[~mask_va]\n",
    "\n",
    "    pipe = make_global_pipeline(num_cols, C=best_C)\n",
    "    pipe.fit(Xtr, ytr)\n",
    "\n",
    "    \n",
    "    scores = pipe.decision_function(Xva)              \n",
    "    preds  = (scores >= 0).astype(int)                # 0 threshold for hinge\n",
    "\n",
    "    cv_scores.append({\n",
    "        \"fold\": k,\n",
    "        \"roc_auc\": roc_auc_score(yva, scores),\n",
    "        \"accuracy\": accuracy_score(yva, preds),\n",
    "        \"n_val\": len(Xva)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbaa39b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'final_auc': 0.5352621760548336, 'final_acc': 0.4633724699272492}\n"
     ]
    }
   ],
   "source": [
    "# 4) final test\n",
    "X_ins, y_ins, X_test, y_test = build_global_insample_and_test(collection)\n",
    "num_cols = [c for c in X_ins.columns if c not in (\"__ticker__\", \"Date\")]\n",
    "\n",
    "mask_ins  = X_ins[num_cols].isna().any(axis=1)\n",
    "X_ins     = X_ins.loc[~mask_ins]\n",
    "y_ins     = y_ins.loc[~mask_ins]\n",
    "\n",
    "mask_test = X_test[num_cols].isna().any(axis=1)\n",
    "X_test    = X_test.loc[~mask_test]\n",
    "y_test    = y_test.loc[~mask_test]\n",
    "\n",
    "final_pipe = make_global_pipeline(num_cols, C=best_C)\n",
    "final_pipe.fit(X_ins, y_ins)\n",
    "\n",
    "final_auc = roc_auc_score(y_test, final_pipe.decision_function(X_test))\n",
    "final_acc = accuracy_score(y_test, (final_pipe.decision_function(X_test) >= 0).astype(int))\n",
    "print({\"final_auc\": final_auc, \"final_acc\": final_acc})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973165a",
   "metadata": {},
   "source": [
    "output:\n",
    "{'final_auc': 0.5352621760548336, 'final_acc': 0.4633724699272492}\n",
    "\n",
    "This is not great, as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5916454e",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f59daba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
