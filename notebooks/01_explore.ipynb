{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1b6d87d-81a6-4a29-9802-df792a1db093",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from src.data_eng.pipeline import run_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc14d94f",
   "metadata": {},
   "source": [
    "Creates a single feature (1 day return) and adds the default target (5 day horizon +1% return) on the tickers from the ticker list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38a16fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first set data config\n",
    "\n",
    "from src.config import Config\n",
    "\n",
    "conf = Config(\n",
    "    features=['r_1d'],\n",
    "    target={'horizon': 5, 'threshold': 0.01},\n",
    "    #ticker_list=['AAPL','META'],\n",
    "    train_cutoff='2010-01-01',         # ignored by folds, but keep for provenance\n",
    "    validate_cutoff='2022-01-01',      # FINAL TEST START\n",
    "    fold_len='365D',\n",
    "    fold_mode='expanding',             # or 'sliding'\n",
    "    sliding_train_years=None,          # set e.g. 5 if using sliding\n",
    "    embargo_days=None                  # defaults to horizon=5\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd177a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin fetching data from yfinance...\n",
      "['AAPL', 'MSFT', 'NVDA', 'GOOGL', 'AMZN', 'META', 'TSLA', 'AVGO', 'TSM', 'ORCL', 'WMT', 'JPM', 'INTC', 'UNH', 'HD']\n",
      "saved: ../data/raw/AAPL.csv\n",
      "saved: ../data/raw/MSFT.csv\n",
      "saved: ../data/raw/NVDA.csv\n",
      "saved: ../data/raw/GOOGL.csv\n",
      "saved: ../data/raw/AMZN.csv\n",
      "saved: ../data/raw/META.csv\n",
      "saved: ../data/raw/TSLA.csv\n",
      "saved: ../data/raw/AVGO.csv\n",
      "saved: ../data/raw/TSM.csv\n",
      "saved: ../data/raw/ORCL.csv\n",
      "saved: ../data/raw/WMT.csv\n",
      "saved: ../data/raw/JPM.csv\n",
      "saved: ../data/raw/INTC.csv\n",
      "saved: ../data/raw/UNH.csv\n",
      "saved: ../data/raw/HD.csv\n",
      "done fetching data\n",
      "being data cleaning...\n",
      "done cleaning data\n",
      "begin feature engineering\n",
      "make features for AAPL\n",
      "make features for MSFT\n",
      "make features for NVDA\n",
      "make features for GOOGL\n",
      "make features for AMZN\n",
      "make features for META\n",
      "make features for TSLA\n",
      "make features for AVGO\n",
      "make features for TSM\n",
      "make features for ORCL\n",
      "make features for WMT\n",
      "make features for JPM\n",
      "make features for INTC\n",
      "make features for UNH\n",
      "make features for HD\n",
      "Done egineering features\n",
      "writing csvs...\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/AAPL.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/MSFT.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/NVDA.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/GOOGL.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/AMZN.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/META.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/TSLA.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/AVGO.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/TSM.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/ORCL.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/WMT.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/JPM.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/INTC.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/UNH.csv\n",
      "saved: /Users/mike/Documents/GitHub/StockPrediction/data/processed/HD.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "run_pipeline(conf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085a54f0",
   "metadata": {},
   "source": [
    "Read the Data back in after processing to a data bundle. This pre splits our data into Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f86d265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5039659597311426"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "from src.data_eng.folds import load_multi_ticker_collection\n",
    "from src.modeling.global_pairs import build_global_fold_pairs, build_global_insample_and_test\n",
    "\n",
    "# 1) get data\n",
    "collection = load_multi_ticker_collection(conf)\n",
    "\n",
    "# 2) build global fold pairs\n",
    "pairs = build_global_fold_pairs(collection)\n",
    "\n",
    "# 3) simple CV loop for a global model\n",
    "def make_global_pipeline(numeric_cols):\n",
    "    pre = ColumnTransformer([\n",
    "        (\"num\", StandardScaler(), numeric_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), [\"__ticker__\"]),\n",
    "    ])\n",
    "    return Pipeline([\n",
    "        (\"pre\", pre),\n",
    "        (\"clf\", LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=3000, random_state=42))\n",
    "    ])\n",
    "\n",
    "cv_scores = []\n",
    "for k, (Xtr, ytr, Xva, yva) in enumerate(pairs):\n",
    "    num_cols = [c for c in Xtr.columns if c not in (\"__ticker__\", \"Date\")]\n",
    "    pipe = make_global_pipeline(num_cols)\n",
    "    pipe.fit(Xtr, ytr)\n",
    "    proba = pipe.predict_proba(Xva)[:, 1]\n",
    "    pred  = (proba >= 0.5).astype(int)\n",
    "    cv_scores.append({\n",
    "        \"fold\": k,\n",
    "        \"roc_auc\": roc_auc_score(yva, proba),\n",
    "        \"accuracy\": accuracy_score(yva, pred),\n",
    "        \"n_val\": len(Xva)\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 4) final test, trained once on all pre-test data\n",
    "X_ins, y_ins, X_test, y_test = build_global_insample_and_test(collection)\n",
    "num_cols = [c for c in X_ins.columns if c not in (\"__ticker__\", \"Date\")]\n",
    "final_pipe = make_global_pipeline(num_cols)\n",
    "\n",
    "\n",
    "assert len(X_ins) == len(y_ins)\n",
    "assert len(X_test) == len(y_test)\n",
    "assert set([\"__ticker__\",\"Date\"]).issubset(X_ins.columns)\n",
    "assert \"__ticker__\" in X_test.columns and \"Date\" in X_test.columns\n",
    "assert not X_ins.duplicated(subset=[\"__ticker__\", \"Date\"]).any()\n",
    "\n",
    "\n",
    "\n",
    "final_pipe.fit(X_ins, y_ins)\n",
    "\n",
    "final_auc = roc_auc_score(y_test, final_pipe.predict_proba(X_test)[:, 1])\n",
    "final_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb120279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.03, 0.49580310839170344, 0.013359730001381975),\n",
       " (0.1, 0.49580310839170344, 0.013359730001381975),\n",
       " (0.3, 0.49580310839170344, 0.013359730001381975),\n",
       " (1, 0.49580310839170344, 0.013359730001381975),\n",
       " (3, 0.4958031083917035, 0.013359730001381995),\n",
       " (10, 0.4958031083917035, 0.013359730001381995)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f48386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
